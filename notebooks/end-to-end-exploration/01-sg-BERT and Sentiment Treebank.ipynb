{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b7cdd8",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "<strike>- Download data</strike>\n",
    "- Re-read transformers blog post and BERT paper\n",
    "<strike>- Fine-tune BERT on dataset</strike>\n",
    "- SHAP values for examples\n",
    "- 1/2 CheckList attacks\n",
    "<strike>- Read vision paper</strike>\n",
    "- Metrics for evaluating explainability change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b9eb2f",
   "metadata": {},
   "source": [
    "# BERT and Sentiment Treebank\n",
    "\n",
    "Fine-tuning code based on [this](https://medium.com/@aniruddha.choudhury94/part-2-bert-fine-tuning-tutorial-with-pytorch-for-text-classification-on-the-corpus-of-linguistic-18057ce330e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2550a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import \\\n",
    "    TensorDataset, \\\n",
    "    DataLoader\n",
    "from transformers import \\\n",
    "    BertTokenizer, \\\n",
    "    BertForSequenceClassification, \\\n",
    "    AdamW, \\\n",
    "    BertConfig, \\\n",
    "    get_linear_schedule_with_warmup\n",
    "import pytreebank\n",
    "from tqdm import tqdm\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c10b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31916ab2",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87eb2cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pytreebank.load_sst(\"data/raw/stanford_sentiment_treebank/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d761d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train']\n",
    "dev = dataset['dev']\n",
    "# test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c608fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanford_raw_to_df(pytree_dataset):\n",
    "    \"\"\"\n",
    "    Convert list of pytreebank LabeledTree objects to DataFrame of full-sentence examples with labels\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    sentences = []\n",
    "    \n",
    "    for labeled_tree_obj in pytree_dataset:\n",
    "        lab, sent = labeled_tree_obj.to_labeled_lines()[0]  # First index contains full sentence\n",
    "        labels.append(lab)\n",
    "        sentences.append(sent)\n",
    "        \n",
    "    output_df = pd.DataFrame(\n",
    "        {\n",
    "            'sentence': sentences,\n",
    "            'label': labels\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "168873ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8544, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0  The Rock is destined to be the 21st Century 's...      3\n",
       "1  The gorgeously elaborate continuation of `` Th...      4\n",
       "2  Singer/composer Bryan Adams contributes a slew...      3\n",
       "3  You 'd think by now America would have had eno...      2\n",
       "4               Yet the act is still charming here .      3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = stanford_raw_to_df(train)\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "971f9197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8544 entries, 0 to 8543\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  8544 non-null   object\n",
      " 1   label     8544 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 133.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cb717b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1101, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It 's a lovely film with lovely performances b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No one goes unindicted here , which is probabl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And if you 're not nearly moved to tears by a ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A warm , funny , engaging film .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uses sharp humor and insight into human nature...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0  It 's a lovely film with lovely performances b...      3\n",
       "1  No one goes unindicted here , which is probabl...      2\n",
       "2  And if you 're not nearly moved to tears by a ...      3\n",
       "3                   A warm , funny , engaging film .      4\n",
       "4  Uses sharp humor and insight into human nature...      4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df = stanford_raw_to_df(dev)\n",
    "print(dev_df.shape)\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadee580",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2f65b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34ec3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_sentences = []\n",
    "\n",
    "for sentence in train_df['sentence'].values:\n",
    "    enc_sent_as_list = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    train_encoded_sentences.append(enc_sent_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13bd5a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Singer/composer Bryan Adams contributes a slew of songs -- a few potential hits , a few more simply intrusive to the story -- but the whole package certainly captures the intended , er , spirit of the piece .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[2]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "793ff52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'singer',\n",
       " '/',\n",
       " 'composer',\n",
       " 'bryan',\n",
       " 'adams',\n",
       " 'contributes',\n",
       " 'a',\n",
       " 'sl',\n",
       " '##ew',\n",
       " 'of',\n",
       " 'songs',\n",
       " '-',\n",
       " '-',\n",
       " 'a',\n",
       " 'few',\n",
       " 'potential',\n",
       " 'hits',\n",
       " ',',\n",
       " 'a',\n",
       " 'few',\n",
       " 'more',\n",
       " 'simply',\n",
       " 'int',\n",
       " '##rus',\n",
       " '##ive',\n",
       " 'to',\n",
       " 'the',\n",
       " 'story',\n",
       " '-',\n",
       " '-',\n",
       " 'but',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'package',\n",
       " 'certainly',\n",
       " 'captures',\n",
       " 'the',\n",
       " 'intended',\n",
       " ',',\n",
       " 'er',\n",
       " ',',\n",
       " 'spirit',\n",
       " 'of',\n",
       " 'the',\n",
       " 'piece',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.convert_ids_to_tokens(i_d) for i_d in train_encoded_sentences[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad173a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_encoded_sentences = []\n",
    "\n",
    "for sentence in dev_df['sentence'].values:\n",
    "    enc_sent_as_list = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    dev_encoded_sentences.append(enc_sent_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fef8079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 55)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(sent) for sent in train_encoded_sentences]), max([len(sent) for sent in dev_encoded_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f02db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_at_end(sentence, max_length):\n",
    "    \"\"\"\n",
    "    Pad tokenised sentence with zeros at end\n",
    "    \n",
    "    :param: sentence: list of encodings for a sentence\n",
    "    :param: max_length: max length to pad up to\n",
    "    \"\"\"\n",
    "    num_zeros_to_add = max_length - len(sentence)\n",
    "    zero_list = list(\n",
    "        np.zeros(num_zeros_to_add).astype(int)\n",
    "    )\n",
    "    padded_sentence = sentence + zero_list\n",
    "    return np.array(padded_sentence)\n",
    "\n",
    "\n",
    "def create_sentence_input_arrays(list_encoded_sentences, max_length):\n",
    "    \"\"\"\n",
    "    Create input arrays for BERT\n",
    "    \n",
    "    :param: list_encoded_sentences: List of sentence encoding lists\n",
    "    :param: max_length: max length to pad up to\n",
    "    \"\"\"\n",
    "    encoded_sentences = [pad_sentence_at_end(sent, max_length) for sent in list_encoded_sentences]\n",
    "    \n",
    "    train_array = np.vstack(encoded_sentences)\n",
    "    \n",
    "    train_attention_mask_array = (train_array != 0).astype(int)\n",
    "    \n",
    "    return train_array, train_attention_mask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b35f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 70\n",
    "\n",
    "train_array, train_attention_mask_array = create_sentence_input_arrays(\n",
    "    train_encoded_sentences, \n",
    "    MAX_LENGTH\n",
    ")\n",
    "\n",
    "dev_array, dev_attention_mask_array = create_sentence_input_arrays(\n",
    "    dev_encoded_sentences, \n",
    "    MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "056a0bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8544, 70), (8544, 70))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array.shape, train_attention_mask_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e0912e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1101, 70), (1101, 70))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_array.shape, dev_attention_mask_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb2cd22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101,  1996,  2600,  2003, 16036,  2000,  2022,  1996,  7398,\n",
       "        2301,  1005,  1055,  2047,  1036,  1036, 16608,  1005,  1005,\n",
       "        1998,  2008,  2002,  1005,  1055,  2183,  2000,  2191,  1037,\n",
       "       17624,  2130,  3618,  2084,  7779, 29058,  8625, 13327,  1010,\n",
       "        3744,  1011, 18856, 19513,  3158,  5477,  4168,  2030,  7112,\n",
       "       16562,  2140,  1012,   102])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_encoded_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a52d34fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101,  1996,  2600,  2003, 16036,  2000,  2022,  1996,  7398,\n",
       "        2301,  1005,  1055,  2047,  1036,  1036, 16608,  1005,  1005,\n",
       "        1998,  2008,  2002,  1005,  1055,  2183,  2000,  2191,  1037,\n",
       "       17624,  2130,  3618,  2084,  7779, 29058,  8625, 13327,  1010,\n",
       "        3744,  1011, 18856, 19513,  3158,  5477,  4168,  2030,  7112,\n",
       "       16562,  2140,  1012,   102,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77ac6bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_attention_mask_array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b42ab",
   "metadata": {},
   "source": [
    "Convert to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13366217",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = torch.tensor(train_array)\n",
    "train_attention_mask_tensor = torch.tensor(train_attention_mask_array)\n",
    "train_labels_tensor = torch.tensor(train_df['label'].values)\n",
    "\n",
    "dev_tensor = torch.tensor(dev_array)\n",
    "dev_attention_mask_tensor = torch.tensor(dev_attention_mask_array)\n",
    "dev_labels_tensor = torch.tensor(dev_df['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc3aac",
   "metadata": {},
   "source": [
    "## Fine-tune BERT\n",
    "\n",
    "Run on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca77c9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fae37fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "EPS = 1e-8\n",
    "RANDOM_SEED = 3\n",
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa8bdfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_tensor, train_attention_mask_tensor, train_labels_tensor)\n",
    "dev_dataset = TensorDataset(dev_tensor, dev_attention_mask_tensor, dev_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9bfb32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_data_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025f4958",
   "metadata": {},
   "source": [
    "https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fff6ac99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=5,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f13d9c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc64bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = AdamW(\n",
    "    bert_model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    eps=EPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb0a44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimiser, \n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(train_data_loader) * NUM_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8395c622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    #========================================#\n",
    "    # TRAINING                               #\n",
    "    #========================================#\n",
    "    \n",
    "    bert_model.train()\n",
    "    \n",
    "    for batch in tqdm(train_data_loader):\n",
    "        \n",
    "        batch_input_ids = batch[0].to(device)\n",
    "        batch_attention_mask = batch[1].to(device)\n",
    "        batch_labels = batch[2].to(device)\n",
    "\n",
    "        optimiser.zero_grad()  # Set gradients to 0 otherwise will accumulate\n",
    "\n",
    "        outputs = bert_model(\n",
    "            input_ids=batch_input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=batch_attention_mask,\n",
    "            labels=batch_labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), 1.0)\n",
    "        \n",
    "        optimiser.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    #========================================#\n",
    "    # EVALUATE                               #\n",
    "    #========================================#  \n",
    "    \n",
    "    bert_model.eval()\n",
    "    \n",
    "    # Train accuracy:\n",
    "    train_pred_labels = []\n",
    "    train_labels = []\n",
    "    \n",
    "    for batch in train_data_loader:\n",
    "        \n",
    "        batch_input_ids = batch[0].to(device)\n",
    "        batch_attention_mask = batch[1].to(device)\n",
    "        batch_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(\n",
    "                input_ids=batch_input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=batch_attention_mask\n",
    "            )\n",
    "            \n",
    "        logits = outputs[0]\n",
    "        \n",
    "        batch_pred_labels = list(\n",
    "            torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        )\n",
    "        train_pred_labels = train_pred_labels + batch_pred_labels\n",
    "        \n",
    "        batch_labels = list(\n",
    "            batch_labels.cpu().numpy()\n",
    "        )\n",
    "        train_labels = train_labels + batch_labels\n",
    "    \n",
    "    train_accuracy = (np.array(train_pred_labels) == np.array(train_labels)).mean()\n",
    "    \n",
    "    \n",
    "    # Dev accuracy:\n",
    "    dev_pred_labels = []\n",
    "    dev_labels = []\n",
    "    \n",
    "    for batch in dev_data_loader:\n",
    "        \n",
    "        batch_input_ids = batch[0].to(device)\n",
    "        batch_attention_mask = batch[1].to(device)\n",
    "        batch_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(\n",
    "                input_ids=batch_input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=batch_attention_mask\n",
    "            )\n",
    "            \n",
    "        logits = outputs[0]\n",
    "        \n",
    "        batch_pred_labels = list(\n",
    "            torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        )\n",
    "        dev_pred_labels = dev_pred_labels + batch_pred_labels\n",
    "        \n",
    "        batch_labels = list(\n",
    "            batch_labels.cpu().numpy()\n",
    "        )\n",
    "        dev_labels = dev_labels + batch_labels\n",
    "    \n",
    "    dev_accuracy = (np.array(dev_pred_labels) == np.array(dev_labels)).mean()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: train_acc={train_accuracy}, dev_acc={dev_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4a8a0",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d665ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c102f",
   "metadata": {},
   "source": [
    "May need to change current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.save_pretrained(\"Colab Notebooks/fine-tuned-bert-base-sst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b14a73",
   "metadata": {},
   "source": [
    "Download and save to models folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701b730",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "449f2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertForSequenceClassification.from_pretrained(\"models/fine-tuned-bert-base-sst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a82bdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:18<00:00,  3.97s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5213442325158947"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.eval()\n",
    "\n",
    "# Dev accuracy:\n",
    "dev_pred_labels = []\n",
    "dev_labels = []\n",
    "\n",
    "for batch in tqdm(dev_data_loader):\n",
    "\n",
    "    batch_input_ids = batch[0].to(device)\n",
    "    batch_attention_mask = batch[1].to(device)\n",
    "    batch_labels = batch[2].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(\n",
    "            input_ids=batch_input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=batch_attention_mask\n",
    "        )\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    batch_pred_labels = list(\n",
    "        torch.argmax(logits, dim=1).cpu().numpy()\n",
    "    )\n",
    "    dev_pred_labels = dev_pred_labels + batch_pred_labels\n",
    "\n",
    "    batch_labels = list(\n",
    "        batch_labels.cpu().numpy()\n",
    "    )\n",
    "    dev_labels = dev_labels + batch_labels\n",
    "\n",
    "dev_accuracy = (np.array(dev_pred_labels) == np.array(dev_labels)).mean()\n",
    "dev_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d132d",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06341a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
