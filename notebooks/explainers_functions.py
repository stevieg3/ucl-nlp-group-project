# -*- coding: utf-8 -*-
"""Explainers_Functions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cpQCmUqg3BExxwSxRvHKt9sXvck5Tg-_
"""

from abc import ABC, abstractmethod
from overrides import overrides
import typing
import shap
import torch
from lime.lime_text import LimeTextExplainer
import numpy as np

class Explainer:
    def __init__(self):
        pass

    @abstractmethod
    def explain_instance(self,s:str)->typing.Any:
      '''
      s - input string
      returns - tokens, weights
      '''
      pass

    @abstractmethod
    def explain_instances(self,S:typing.List[str])->typing.Any:
      '''
      S - list of strings
      returns - tokens, weights
      '''
      pass

class LimeExplainer(Explainer):

  def __init__(self,model,tokenizer,labels,device,model_type='BERT'):
    '''
    predict_proba - predict function which will depend on model type
    '''
    self.exp = LimeTextExplainer(class_names=labels)
    self.model=model
    self.device=device
    self.tokenizer=tokenizer
    if model_type=='BERT':
      self.predict_proba=lambda x:predict_proba_BERT(x,self.model,self.tokenizer,self.device)
    elif model_type=='BCN':
      self.predict_proba=lambda x:predict_proba_BCN(x,self.model)

  def explain_instance(self,x):
    '''
    x - 1 input instance
    
    returns - list of top tokens/importance weights
    '''
    exp_instance=self.exp.explain_instance(x, self.predict_proba, num_features=10,top_labels=5,num_samples=50)

    pred_label = np.argmax(exp_instance.predict_proba)

    top_tokens=[x[0] for x in exp_instance.as_list(label=pred_label)]
    top_values = [x[1] for x in exp_instance.as_list(label=pred_label)]

    return top_tokens,top_values

  @overrides
  def explain_instances(self,X):
    '''
    X - array of input sentences
    '''

    top_tokens_list=[]
    top_values_list = []

    for s in X:

      top_tokens,top_values = self.explain_instance(s)

      top_tokens_list.append(top_tokens)
      top_values_list.append(top_values)

    return top_tokens_list,top_values_list

class SHAPExplainer(Explainer):

  def __init__(self, model,tokenizer,labels,device):
    '''
    Currently works only with BERT
    '''
    self.model=model
    self.tokenizer=tokenizer
    self.device=device
    self.predict_proba = lambda x: predict_proba_BERT(x,model,tokenizer,device)
    self.exp=shap.Explainer(self.predict_proba,self.tokenizer,output_names=labels)

  @overrides
  def explain_instances(self,X):
    '''
    X - array of input sentences
    '''

    shap_values = self.exp(X)

    tokens,values=shap_values.data,shap_values.values

    return tokens,values

  @overrides
  def explain_instance(self,x):
    '''
    shap explainer can process lists by default
    '''
    pass

def predict_proba_BERT(x,model,tokenizer,device):

  '''
  this depends on the model, will be passed to explainer
  '''

  if isinstance(x,str):
    x=[x]

  with torch.no_grad():
    tv = torch.tensor([tokenizer.encode(v, padding='max_length', max_length=128,truncation=True) for v in x]).to(device)
    attention_mask = (tv!=0).type(torch.int64).to(device)
    outputs = model(tv,attention_mask=attention_mask)
    scores = torch.softmax(outputs[0],dim=1)

    return scores.cpu().detach().numpy()

def predict_proba_BCN(x,BCN_predictor):

  #predict only on the sentence
  title = ' '

  a = BCN_predictor.predict_batch_json([
      dict(title=title, Description=s) for s in x
  ])

  class_probs=np.array([t['class_probabilities'] for t in a])
  return class_probs