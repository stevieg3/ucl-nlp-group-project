{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from allennlp.data.tokenizers.spacy_tokenizer import SpacyTokenizer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# need to filter warnings related to spacy lemmatizer\n",
    "logger = logging.getLogger(\"spacy\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PathDistribution' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3b77ff06b4f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_sst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_agnews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/ucl-nlp-group-project/src/data/dataload.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytreebank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-group-project/lib/python3.7/site-packages/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcatenate_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-group-project/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBinaryIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-group-project/lib/python3.7/site-packages/fsspec/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry_points\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mentry_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# importlib-metadata < 0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-group-project/lib/python3.7/site-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36mentry_points\u001b[0;34m(**params)\u001b[0m\n\u001b[1;32m    883\u001b[0m         \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_points\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     )\n\u001b[0;32m--> 885\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSelectableGroups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-group-project/lib/python3.7/site-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, eps)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mby_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'group'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mordered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEntryPoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-group-project/lib/python3.7/site-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_everseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     eps = itertools.chain.from_iterable(\n\u001b[0;32m--> 883\u001b[0;31m         \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_points\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m     )\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSelectableGroups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-group-project/lib/python3.7/site-packages/importlib_metadata/_itertools.py\u001b[0m in \u001b[0;36munique_everseen\u001b[0;34m(iterable, key)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mseen_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PathDistribution' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "from src.data.dataload import load_sst\n",
    "from src.data.dataload import load_agnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.perturbations import add_perturbations\n",
    "from src.data.perturbations import \\\n",
    "    remove_commas, \\\n",
    "    remove_all_punctuation, \\\n",
    "    switch_gender, \\\n",
    "    strip_trailing_punct, \\\n",
    "    add_typo, \\\n",
    "    change_first_name, \\\n",
    "    change_last_name, \\\n",
    "    change_location, \\\n",
    "    contraction, \\\n",
    "    swap_adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = load_sst()\n",
    "agnews = load_agnews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {'sst': sst, 'agnews': agnews}\n",
    "datasets = list(input_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/stevengeorge/.cache/huggingface/datasets/ag_news/default/0.0.0/17ec33e23df9e89565131f989e0fdf78b0cc4672337b582da83fc3c9f79fe34d)\n"
     ]
    }
   ],
   "source": [
    "train = {}\n",
    "dev = {}\n",
    "test = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    train[dataset], dev[dataset], test[dataset] = input_data[dataset].train_val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8544, 2) (1101, 2) (2210, 2)\n",
      "(108000, 3) (12000, 3) (7600, 3)\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(train[dataset].shape, dev[dataset].shape, test[dataset].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>2</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>2</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters - Soaring crude prices plus worriesabo...</td>\n",
       "      <td>2</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters - Authorities have halted oil exportfl...</td>\n",
       "      <td>2</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>2</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  \\\n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...      2   \n",
       "1  Reuters - Private investment firm Carlyle Grou...      2   \n",
       "2  Reuters - Soaring crude prices plus worriesabo...      2   \n",
       "3  Reuters - Authorities have halted oil exportfl...      2   \n",
       "4  AFP - Tearaway world oil prices, toppling reco...      2   \n",
       "\n",
       "                                               title  \n",
       "0  Wall St. Bears Claw Back Into the Black (Reuters)  \n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...  \n",
       "2    Oil and Economy Cloud Stocks' Outlook (Reuters)  \n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...  \n",
       "4  Oil prices soar to all-time record, posing new...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['agnews'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "train_subset = train['sst'].copy().sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>Schnieder bounces around with limp wrists , we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>Mr. Goyer 's loose , unaccountable direction i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>Director Nancy Savoca 's no-frills record of a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>An average coming-of-age tale elevated by the ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label\n",
       "6341  Schnieder bounces around with limp wrists , we...      1\n",
       "2119  It is an indelible epic American story about t...      2\n",
       "5105  Mr. Goyer 's loose , unaccountable direction i...      0\n",
       "1594  Director Nancy Savoca 's no-frills record of a...      4\n",
       "387   An average coming-of-age tale elevated by the ...      2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SpacyTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 816 ms, sys: 131 ms, total: 947 ms\n",
      "Wall time: 953 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_perturbations = add_perturbations(\n",
    "    df=train_subset,\n",
    "    tokenizer=tokenizer,\n",
    "    sentence_col_name='sentence', \n",
    "    perturbation_functions=[\n",
    "        remove_commas,\n",
    "        remove_all_punctuation,\n",
    "        switch_gender,\n",
    "        strip_trailing_punct,\n",
    "        add_typo,\n",
    "        change_first_name,\n",
    "        change_last_name,\n",
    "        change_location,\n",
    "        contraction,\n",
    "        swap_adjectives\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens_orig</th>\n",
       "      <th>remove_commas_concat</th>\n",
       "      <th>remove_commas_tokens</th>\n",
       "      <th>remove_commas_success</th>\n",
       "      <th>remove_commas_pert_ind</th>\n",
       "      <th>remove_all_punct_concat</th>\n",
       "      <th>remove_all_punct_tokens</th>\n",
       "      <th>remove_all_punct_success</th>\n",
       "      <th>...</th>\n",
       "      <th>change_location_success</th>\n",
       "      <th>change_location_pert_ind</th>\n",
       "      <th>contraction_concat</th>\n",
       "      <th>contraction_tokens</th>\n",
       "      <th>contraction_success</th>\n",
       "      <th>contraction_pert_ind</th>\n",
       "      <th>swap_adj_concat</th>\n",
       "      <th>swap_adj_tokens</th>\n",
       "      <th>swap_adj_success</th>\n",
       "      <th>swap_adj_pert_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>Schnieder bounces around with limp wrists , we...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Schnieder, bounces, around, with, limp, wrist...</td>\n",
       "      <td>Schnieder bounces around with limp wrists  wea...</td>\n",
       "      <td>[Schnieder, bounces, around, with, limp, wrist...</td>\n",
       "      <td>1</td>\n",
       "      <td>[6, 14]</td>\n",
       "      <td>Schnieder bounces around with limp wrists  wea...</td>\n",
       "      <td>[Schnieder, bounces, around, with, limp, wrist...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Schnieder bounces around with limp wrists , we...</td>\n",
       "      <td>[Schnieder, bounces, around, with, limp, wrist...</td>\n",
       "      <td>1</td>\n",
       "      <td>[23, 24]</td>\n",
       "      <td>Schnieder bounces around with limp wrists , we...</td>\n",
       "      <td>[Schnieder, bounces, around, with, limp, wrist...</td>\n",
       "      <td>1</td>\n",
       "      <td>[10, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>2</td>\n",
       "      <td>[It, is, an, indelible, epic, American, story,...</td>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>[It, is, an, indelible, epic, American, story,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[10, 16]</td>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>[It, is, an, indelible, epic, American, story,...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>[It, is, an, indelible, epic, American, story,...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>[It, is, an, indelible, epic, American, story,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[12, 14, 22, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>Mr. Goyer 's loose , unaccountable direction i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Mr., Goyer, 's, loose, ,, unaccountable, dire...</td>\n",
       "      <td>Mr. Goyer 's loose  unaccountable direction is...</td>\n",
       "      <td>[Mr., Goyer, 's, loose, , unaccountable, direc...</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Mr Goyer s loose  unaccountable direction is t...</td>\n",
       "      <td>[Mr, Goyer, s, loose, , unaccountable, directi...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr. Goyer 's loose , unaccountable direction i...</td>\n",
       "      <td>[Mr., Goyer, 's, loose, ,, unaccountable, dire...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr. Goyer 's loose , unaccountable direction i...</td>\n",
       "      <td>[Mr., Goyer, 's, loose, ,, unaccountable, dire...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>Director Nancy Savoca 's no-frills record of a...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Director, Nancy, Savoca, 's, no, -, frills, r...</td>\n",
       "      <td>Director Nancy Savoca 's no-frills record of a...</td>\n",
       "      <td>[Director, Nancy, Savoca, 's, no, -, frills, r...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Director Nancy Savoca s no  frills record of a...</td>\n",
       "      <td>[Director, Nancy, Savoca, s, no, , frills, rec...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Director Nancy Savoca 's no-frills record of a...</td>\n",
       "      <td>[Director, Nancy, Savoca, 's, no, -, frills, r...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Director Nancy Savoca 's no - frills record of...</td>\n",
       "      <td>[Director, Nancy, Savoca, 's, no, -, frills, r...</td>\n",
       "      <td>1</td>\n",
       "      <td>[33, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>An average coming-of-age tale elevated by the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[An, average, coming, -, of, -, age, tale, ele...</td>\n",
       "      <td>An average coming-of-age tale elevated by the ...</td>\n",
       "      <td>[An, average, coming, -, of, -, age, tale, ele...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>An average coming  of  age tale elevated by th...</td>\n",
       "      <td>[An, average, coming, , of, , age, tale, eleva...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>An average coming-of-age tale elevated by the ...</td>\n",
       "      <td>[An, average, coming, -, of, -, age, tale, ele...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>An average coming-of-age tale elevated by the ...</td>\n",
       "      <td>[An, average, coming, -, of, -, age, tale, ele...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  \\\n",
       "6341  Schnieder bounces around with limp wrists , we...      1   \n",
       "2119  It is an indelible epic American story about t...      2   \n",
       "5105  Mr. Goyer 's loose , unaccountable direction i...      0   \n",
       "1594  Director Nancy Savoca 's no-frills record of a...      4   \n",
       "387   An average coming-of-age tale elevated by the ...      2   \n",
       "\n",
       "                                            tokens_orig  \\\n",
       "6341  [Schnieder, bounces, around, with, limp, wrist...   \n",
       "2119  [It, is, an, indelible, epic, American, story,...   \n",
       "5105  [Mr., Goyer, 's, loose, ,, unaccountable, dire...   \n",
       "1594  [Director, Nancy, Savoca, 's, no, -, frills, r...   \n",
       "387   [An, average, coming, -, of, -, age, tale, ele...   \n",
       "\n",
       "                                   remove_commas_concat  \\\n",
       "6341  Schnieder bounces around with limp wrists  wea...   \n",
       "2119  It is an indelible epic American story about t...   \n",
       "5105  Mr. Goyer 's loose  unaccountable direction is...   \n",
       "1594  Director Nancy Savoca 's no-frills record of a...   \n",
       "387   An average coming-of-age tale elevated by the ...   \n",
       "\n",
       "                                   remove_commas_tokens  \\\n",
       "6341  [Schnieder, bounces, around, with, limp, wrist...   \n",
       "2119  [It, is, an, indelible, epic, American, story,...   \n",
       "5105  [Mr., Goyer, 's, loose, , unaccountable, direc...   \n",
       "1594  [Director, Nancy, Savoca, 's, no, -, frills, r...   \n",
       "387   [An, average, coming, -, of, -, age, tale, ele...   \n",
       "\n",
       "      remove_commas_success remove_commas_pert_ind  \\\n",
       "6341                      1                [6, 14]   \n",
       "2119                      1               [10, 16]   \n",
       "5105                      1                    [4]   \n",
       "1594                      0                   None   \n",
       "387                       0                   None   \n",
       "\n",
       "                                remove_all_punct_concat  \\\n",
       "6341  Schnieder bounces around with limp wrists  wea...   \n",
       "2119  It is an indelible epic American story about t...   \n",
       "5105  Mr Goyer s loose  unaccountable direction is t...   \n",
       "1594  Director Nancy Savoca s no  frills record of a...   \n",
       "387   An average coming  of  age tale elevated by th...   \n",
       "\n",
       "                                remove_all_punct_tokens  \\\n",
       "6341  [Schnieder, bounces, around, with, limp, wrist...   \n",
       "2119  [It, is, an, indelible, epic, American, story,...   \n",
       "5105  [Mr, Goyer, s, loose, , unaccountable, directi...   \n",
       "1594  [Director, Nancy, Savoca, s, no, , frills, rec...   \n",
       "387   [An, average, coming, , of, , age, tale, eleva...   \n",
       "\n",
       "      remove_all_punct_success  ... change_location_success  \\\n",
       "6341                         1  ...                       0   \n",
       "2119                         1  ...                       0   \n",
       "5105                         1  ...                       0   \n",
       "1594                         1  ...                       0   \n",
       "387                          1  ...                       0   \n",
       "\n",
       "     change_location_pert_ind  \\\n",
       "6341                     None   \n",
       "2119                     None   \n",
       "5105                     None   \n",
       "1594                     None   \n",
       "387                      None   \n",
       "\n",
       "                                     contraction_concat  \\\n",
       "6341  Schnieder bounces around with limp wrists , we...   \n",
       "2119  It is an indelible epic American story about t...   \n",
       "5105  Mr. Goyer 's loose , unaccountable direction i...   \n",
       "1594  Director Nancy Savoca 's no-frills record of a...   \n",
       "387   An average coming-of-age tale elevated by the ...   \n",
       "\n",
       "                                     contraction_tokens contraction_success  \\\n",
       "6341  [Schnieder, bounces, around, with, limp, wrist...                   1   \n",
       "2119  [It, is, an, indelible, epic, American, story,...                   0   \n",
       "5105  [Mr., Goyer, 's, loose, ,, unaccountable, dire...                   0   \n",
       "1594  [Director, Nancy, Savoca, 's, no, -, frills, r...                   0   \n",
       "387   [An, average, coming, -, of, -, age, tale, ele...                   0   \n",
       "\n",
       "     contraction_pert_ind                                    swap_adj_concat  \\\n",
       "6341             [23, 24]  Schnieder bounces around with limp wrists , we...   \n",
       "2119                 None  It is an indelible epic American story about t...   \n",
       "5105                 None  Mr. Goyer 's loose , unaccountable direction i...   \n",
       "1594                 None  Director Nancy Savoca 's no - frills record of...   \n",
       "387                  None  An average coming-of-age tale elevated by the ...   \n",
       "\n",
       "                                        swap_adj_tokens swap_adj_success  \\\n",
       "6341  [Schnieder, bounces, around, with, limp, wrist...                1   \n",
       "2119  [It, is, an, indelible, epic, American, story,...                1   \n",
       "5105  [Mr., Goyer, 's, loose, ,, unaccountable, dire...                0   \n",
       "1594  [Director, Nancy, Savoca, 's, no, -, frills, r...                1   \n",
       "387   [An, average, coming, -, of, -, age, tale, ele...                0   \n",
       "\n",
       "     swap_adj_pert_ind  \n",
       "6341          [10, 12]  \n",
       "2119  [12, 14, 22, 24]  \n",
       "5105              None  \n",
       "1594          [33, 35]  \n",
       "387               None  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_perturbations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['remove_commas_tokens',\n",
       " 'remove_all_punct_tokens',\n",
       " 'switch_gender_tokens',\n",
       " 'strip_punct_tokens',\n",
       " 'add_typo_tokens',\n",
       " 'change_first_name_tokens',\n",
       " 'change_last_name_tokens',\n",
       " 'change_location_tokens',\n",
       " 'contraction_tokens',\n",
       " 'swap_adj_tokens']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturb_columns = [col for col in train_perturbations.columns if '_tokens' in col]\n",
    "perturb_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not true for strip_punct_tokens\n"
     ]
    }
   ],
   "source": [
    "for col in perturb_columns:\n",
    "    try:\n",
    "        assert (train_perturbations['tokens_orig'].apply(len) != train_perturbations[col].apply(len)).sum() == 0\n",
    "    except AssertionError:\n",
    "        print(f'Not true for {col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 816 ms, sys: 131 ms, total: 947 ms\n",
      "Wall time: 953 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_perturbations = add_perturbations(\n",
    "    df=train_subset,\n",
    "    tokenizer=tokenizer,\n",
    "    sentence_col_name='sentence', \n",
    "    perturbation_functions=[\n",
    "        remove_commas,\n",
    "        remove_all_punctuation,\n",
    "        switch_gender,\n",
    "        strip_trailing_punct,\n",
    "        add_typo,\n",
    "        change_first_name,\n",
    "        change_last_name,\n",
    "        change_location,\n",
    "        contraction,\n",
    "        swap_adjectives\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens_orig</th>\n",
       "      <th>remove_commas_concat</th>\n",
       "      <th>remove_commas_tokens</th>\n",
       "      <th>remove_commas_success</th>\n",
       "      <th>remove_commas_pert_ind</th>\n",
       "      <th>remove_all_punct_concat</th>\n",
       "      <th>remove_all_punct_tokens</th>\n",
       "      <th>remove_all_punct_success</th>\n",
       "      <th>...</th>\n",
       "      <th>change_location_success</th>\n",
       "      <th>change_location_pert_ind</th>\n",
       "      <th>contraction_concat</th>\n",
       "      <th>contraction_tokens</th>\n",
       "      <th>contraction_success</th>\n",
       "      <th>contraction_pert_ind</th>\n",
       "      <th>swap_adj_concat</th>\n",
       "      <th>swap_adj_tokens</th>\n",
       "      <th>swap_adj_success</th>\n",
       "      <th>swap_adj_pert_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>Schnieder bounces around with limp wrists , we...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Schnieder, bounces, around, with, limp, wrist...</td>\n",
       "      <td>Schnieder bounces around with limp wrists  wea...</td>\n",
       "      <td>[Schnieder, bounces, around, with, limp, wrist...</td>\n",
       "      <td>1</td>\n",
       "      <td>[6, 14]</td>\n",
       "      <td>Schnieder bounces around with limp wrists  wea...</td>\n",
       "      <td>[Schnieder, bounces, around, with, limp, wrist...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Schnieder bounces around with limp wrists , we...</td>\n",
       "      <td>[Schnieder, bounces, around, with, limp, wrist...</td>\n",
       "      <td>1</td>\n",
       "      <td>[23, 24]</td>\n",
       "      <td>Schnieder bounces around with limp wrists , we...</td>\n",
       "      <td>[Schnieder, bounces, around, with, limp, wrist...</td>\n",
       "      <td>1</td>\n",
       "      <td>[10, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>2</td>\n",
       "      <td>[It, is, an, indelible, epic, American, story,...</td>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>[It, is, an, indelible, epic, American, story,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[10, 16]</td>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>[It, is, an, indelible, epic, American, story,...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>[It, is, an, indelible, epic, American, story,...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>[It, is, an, indelible, epic, American, story,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[12, 14, 22, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>Mr. Goyer 's loose , unaccountable direction i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Mr., Goyer, 's, loose, ,, unaccountable, dire...</td>\n",
       "      <td>Mr. Goyer 's loose  unaccountable direction is...</td>\n",
       "      <td>[Mr., Goyer, 's, loose, , unaccountable, direc...</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Mr Goyer s loose  unaccountable direction is t...</td>\n",
       "      <td>[Mr, Goyer, s, loose, , unaccountable, directi...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr. Goyer 's loose , unaccountable direction i...</td>\n",
       "      <td>[Mr., Goyer, 's, loose, ,, unaccountable, dire...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr. Goyer 's loose , unaccountable direction i...</td>\n",
       "      <td>[Mr., Goyer, 's, loose, ,, unaccountable, dire...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>Director Nancy Savoca 's no-frills record of a...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Director, Nancy, Savoca, 's, no, -, frills, r...</td>\n",
       "      <td>Director Nancy Savoca 's no-frills record of a...</td>\n",
       "      <td>[Director, Nancy, Savoca, 's, no, -, frills, r...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Director Nancy Savoca s no  frills record of a...</td>\n",
       "      <td>[Director, Nancy, Savoca, s, no, , frills, rec...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Director Nancy Savoca 's no-frills record of a...</td>\n",
       "      <td>[Director, Nancy, Savoca, 's, no, -, frills, r...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Director Nancy Savoca 's no - frills record of...</td>\n",
       "      <td>[Director, Nancy, Savoca, 's, no, -, frills, r...</td>\n",
       "      <td>1</td>\n",
       "      <td>[33, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>An average coming-of-age tale elevated by the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[An, average, coming, -, of, -, age, tale, ele...</td>\n",
       "      <td>An average coming-of-age tale elevated by the ...</td>\n",
       "      <td>[An, average, coming, -, of, -, age, tale, ele...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>An average coming  of  age tale elevated by th...</td>\n",
       "      <td>[An, average, coming, , of, , age, tale, eleva...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>An average coming-of-age tale elevated by the ...</td>\n",
       "      <td>[An, average, coming, -, of, -, age, tale, ele...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>An average coming-of-age tale elevated by the ...</td>\n",
       "      <td>[An, average, coming, -, of, -, age, tale, ele...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  \\\n",
       "6341  Schnieder bounces around with limp wrists , we...      1   \n",
       "2119  It is an indelible epic American story about t...      2   \n",
       "5105  Mr. Goyer 's loose , unaccountable direction i...      0   \n",
       "1594  Director Nancy Savoca 's no-frills record of a...      4   \n",
       "387   An average coming-of-age tale elevated by the ...      2   \n",
       "\n",
       "                                            tokens_orig  \\\n",
       "6341  [Schnieder, bounces, around, with, limp, wrist...   \n",
       "2119  [It, is, an, indelible, epic, American, story,...   \n",
       "5105  [Mr., Goyer, 's, loose, ,, unaccountable, dire...   \n",
       "1594  [Director, Nancy, Savoca, 's, no, -, frills, r...   \n",
       "387   [An, average, coming, -, of, -, age, tale, ele...   \n",
       "\n",
       "                                   remove_commas_concat  \\\n",
       "6341  Schnieder bounces around with limp wrists  wea...   \n",
       "2119  It is an indelible epic American story about t...   \n",
       "5105  Mr. Goyer 's loose  unaccountable direction is...   \n",
       "1594  Director Nancy Savoca 's no-frills record of a...   \n",
       "387   An average coming-of-age tale elevated by the ...   \n",
       "\n",
       "                                   remove_commas_tokens  \\\n",
       "6341  [Schnieder, bounces, around, with, limp, wrist...   \n",
       "2119  [It, is, an, indelible, epic, American, story,...   \n",
       "5105  [Mr., Goyer, 's, loose, , unaccountable, direc...   \n",
       "1594  [Director, Nancy, Savoca, 's, no, -, frills, r...   \n",
       "387   [An, average, coming, -, of, -, age, tale, ele...   \n",
       "\n",
       "      remove_commas_success remove_commas_pert_ind  \\\n",
       "6341                      1                [6, 14]   \n",
       "2119                      1               [10, 16]   \n",
       "5105                      1                    [4]   \n",
       "1594                      0                   None   \n",
       "387                       0                   None   \n",
       "\n",
       "                                remove_all_punct_concat  \\\n",
       "6341  Schnieder bounces around with limp wrists  wea...   \n",
       "2119  It is an indelible epic American story about t...   \n",
       "5105  Mr Goyer s loose  unaccountable direction is t...   \n",
       "1594  Director Nancy Savoca s no  frills record of a...   \n",
       "387   An average coming  of  age tale elevated by th...   \n",
       "\n",
       "                                remove_all_punct_tokens  \\\n",
       "6341  [Schnieder, bounces, around, with, limp, wrist...   \n",
       "2119  [It, is, an, indelible, epic, American, story,...   \n",
       "5105  [Mr, Goyer, s, loose, , unaccountable, directi...   \n",
       "1594  [Director, Nancy, Savoca, s, no, , frills, rec...   \n",
       "387   [An, average, coming, , of, , age, tale, eleva...   \n",
       "\n",
       "      remove_all_punct_success  ... change_location_success  \\\n",
       "6341                         1  ...                       0   \n",
       "2119                         1  ...                       0   \n",
       "5105                         1  ...                       0   \n",
       "1594                         1  ...                       0   \n",
       "387                          1  ...                       0   \n",
       "\n",
       "     change_location_pert_ind  \\\n",
       "6341                     None   \n",
       "2119                     None   \n",
       "5105                     None   \n",
       "1594                     None   \n",
       "387                      None   \n",
       "\n",
       "                                     contraction_concat  \\\n",
       "6341  Schnieder bounces around with limp wrists , we...   \n",
       "2119  It is an indelible epic American story about t...   \n",
       "5105  Mr. Goyer 's loose , unaccountable direction i...   \n",
       "1594  Director Nancy Savoca 's no-frills record of a...   \n",
       "387   An average coming-of-age tale elevated by the ...   \n",
       "\n",
       "                                     contraction_tokens contraction_success  \\\n",
       "6341  [Schnieder, bounces, around, with, limp, wrist...                   1   \n",
       "2119  [It, is, an, indelible, epic, American, story,...                   0   \n",
       "5105  [Mr., Goyer, 's, loose, ,, unaccountable, dire...                   0   \n",
       "1594  [Director, Nancy, Savoca, 's, no, -, frills, r...                   0   \n",
       "387   [An, average, coming, -, of, -, age, tale, ele...                   0   \n",
       "\n",
       "     contraction_pert_ind                                    swap_adj_concat  \\\n",
       "6341             [23, 24]  Schnieder bounces around with limp wrists , we...   \n",
       "2119                 None  It is an indelible epic American story about t...   \n",
       "5105                 None  Mr. Goyer 's loose , unaccountable direction i...   \n",
       "1594                 None  Director Nancy Savoca 's no - frills record of...   \n",
       "387                  None  An average coming-of-age tale elevated by the ...   \n",
       "\n",
       "                                        swap_adj_tokens swap_adj_success  \\\n",
       "6341  [Schnieder, bounces, around, with, limp, wrist...                1   \n",
       "2119  [It, is, an, indelible, epic, American, story,...                1   \n",
       "5105  [Mr., Goyer, 's, loose, ,, unaccountable, dire...                0   \n",
       "1594  [Director, Nancy, Savoca, 's, no, -, frills, r...                1   \n",
       "387   [An, average, coming, -, of, -, age, tale, ele...                0   \n",
       "\n",
       "     swap_adj_pert_ind  \n",
       "6341          [10, 12]  \n",
       "2119  [12, 14, 22, 24]  \n",
       "5105              None  \n",
       "1594          [33, 35]  \n",
       "387               None  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_perturbations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['remove_commas_tokens',\n",
       " 'remove_all_punct_tokens',\n",
       " 'switch_gender_tokens',\n",
       " 'strip_punct_tokens',\n",
       " 'add_typo_tokens',\n",
       " 'change_first_name_tokens',\n",
       " 'change_last_name_tokens',\n",
       " 'change_location_tokens',\n",
       " 'contraction_tokens',\n",
       " 'swap_adj_tokens']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturb_columns = [col for col in train_perturbations.columns if '_tokens' in col]\n",
    "perturb_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not true for strip_punct_tokens\n"
     ]
    }
   ],
   "source": [
    "for col in perturb_columns:\n",
    "    try:\n",
    "        assert (train_perturbations['tokens_orig'].apply(len) != train_perturbations[col].apply(len)).sum() == 0\n",
    "    except AssertionError:\n",
    "        print(f'Not true for {col}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
