{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "# need to filter warnings related to spacy lemmatizer\n",
    "import logging\n",
    "logger = logging.getLogger(\"spacy\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataload import load_sst\n",
    "from src.data.dataload import load_agnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.perturbations import add_perturbations\n",
    "from src.data.perturbations import \\\n",
    "    remove_commas, \\\n",
    "    remove_all_punctuation, \\\n",
    "    switch_gender, \\\n",
    "    strip_trailing_punct, \\\n",
    "    add_typo, \\\n",
    "    change_first_name, \\\n",
    "    change_last_name, \\\n",
    "    change_location, \\\n",
    "    contraction, \\\n",
    "    swap_adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = load_sst()\n",
    "agnews = load_agnews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {'sst': sst, 'agnews': agnews}\n",
    "datasets = list(input_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/stevengeorge/.cache/huggingface/datasets/ag_news/default/0.0.0/17ec33e23df9e89565131f989e0fdf78b0cc4672337b582da83fc3c9f79fe34d)\n"
     ]
    }
   ],
   "source": [
    "train = {}\n",
    "dev = {}\n",
    "test = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    train[dataset], dev[dataset], test[dataset] = input_data[dataset].train_val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8544, 2) (1101, 2) (2210, 2)\n",
      "(108000, 3) (12000, 3) (7600, 3)\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(train[dataset].shape, dev[dataset].shape, test[dataset].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>2</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>2</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters - Soaring crude prices plus worriesabo...</td>\n",
       "      <td>2</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters - Authorities have halted oil exportfl...</td>\n",
       "      <td>2</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>2</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  \\\n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...      2   \n",
       "1  Reuters - Private investment firm Carlyle Grou...      2   \n",
       "2  Reuters - Soaring crude prices plus worriesabo...      2   \n",
       "3  Reuters - Authorities have halted oil exportfl...      2   \n",
       "4  AFP - Tearaway world oil prices, toppling reco...      2   \n",
       "\n",
       "                                               title  \n",
       "0  Wall St. Bears Claw Back Into the Black (Reuters)  \n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...  \n",
       "2    Oil and Economy Cloud Stocks' Outlook (Reuters)  \n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...  \n",
       "4  Oil prices soar to all-time record, posing new...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['agnews'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "train_subset = train['sst'].copy().sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>Schnieder bounces around with limp wrists , we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>Mr. Goyer 's loose , unaccountable direction i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>Director Nancy Savoca 's no-frills record of a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>An average coming-of-age tale elevated by the ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label\n",
       "6341  Schnieder bounces around with limp wrists , we...      1\n",
       "2119  It is an indelible epic American story about t...      2\n",
       "5105  Mr. Goyer 's loose , unaccountable direction i...      0\n",
       "1594  Director Nancy Savoca 's no-frills record of a...      4\n",
       "387   An average coming-of-age tale elevated by the ...      2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange() (1,1, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/ucl-nlp-group-project/src/data/perturbations.py\u001b[0m in \u001b[0;36madd_perturbations\u001b[0;34m(df, sentence_col_name, perturbation_functions, seed, tokenizer)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mperturbation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mperturbation_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0mperturbation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_col_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/ucl-nlp-group-project/src/data/perturbations.py\u001b[0m in \u001b[0;36madd_typo\u001b[0;34m(df, sentence_col_name, tokens_orig)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mattempts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mtoken_length\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattempts\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mindex_pert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0mtoken_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_pert\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mattempts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-group-project/lib/python3.7/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-group-project/lib/python3.7/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange() (%d,%d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# Non-unit step argument supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty range for randrange() (1,1, 0)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_perturbations = add_perturbations(\n",
    "    df=train_subset, \n",
    "    sentence_col_name='sentence', \n",
    "    perturbation_functions=[\n",
    "        remove_commas,\n",
    "        remove_all_punctuation,\n",
    "        switch_gender,\n",
    "        strip_trailing_punct,\n",
    "        add_typo,\n",
    "        change_first_name,\n",
    "        change_last_name,\n",
    "        change_location,\n",
    "        contraction,\n",
    "        swap_adjectives\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>sentence_remove_commas_concat</th>\n",
       "      <th>sentence_remove_commas_tokens</th>\n",
       "      <th>success_remove_commas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schnieder bounces around with limp wrists , we...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Schnieder, bounces, around, with, limp, wrist...</td>\n",
       "      <td>Schnieder bounces around with limp wrists  wea...</td>\n",
       "      <td>[Schnieder, bounces, around, with, limp, wrist...</td>\n",
       "      <td>[1, [[6, 14]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>2</td>\n",
       "      <td>[It, is, an, indelible, epic, American, story,...</td>\n",
       "      <td>It is an indelible epic American story about t...</td>\n",
       "      <td>[It, is, an, indelible, epic, American, story,...</td>\n",
       "      <td>[1, [[10, 16]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. Goyer 's loose , unaccountable direction i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Mr., Goyer, 's, loose, ,, unaccountable, dire...</td>\n",
       "      <td>Mr. Goyer 's loose  unaccountable direction is...</td>\n",
       "      <td>[Mr., Goyer, 's, loose, , unaccountable, direc...</td>\n",
       "      <td>[1, [[4]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Director Nancy Savoca 's no-frills record of a...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Director, Nancy, Savoca, 's, no, -, frills, r...</td>\n",
       "      <td>Director Nancy Savoca 's no-frills record of a...</td>\n",
       "      <td>[Director, Nancy, Savoca, 's, no, -, frills, r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An average coming-of-age tale elevated by the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[An, average, coming, -, of, -, age, tale, ele...</td>\n",
       "      <td>An average coming-of-age tale elevated by the ...</td>\n",
       "      <td>[An, average, coming, -, of, -, age, tale, ele...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  \\\n",
       "0  Schnieder bounces around with limp wrists , we...      1   \n",
       "1  It is an indelible epic American story about t...      2   \n",
       "2  Mr. Goyer 's loose , unaccountable direction i...      0   \n",
       "3  Director Nancy Savoca 's no-frills record of a...      4   \n",
       "4  An average coming-of-age tale elevated by the ...      2   \n",
       "\n",
       "                                     sentence_tokens  \\\n",
       "0  [Schnieder, bounces, around, with, limp, wrist...   \n",
       "1  [It, is, an, indelible, epic, American, story,...   \n",
       "2  [Mr., Goyer, 's, loose, ,, unaccountable, dire...   \n",
       "3  [Director, Nancy, Savoca, 's, no, -, frills, r...   \n",
       "4  [An, average, coming, -, of, -, age, tale, ele...   \n",
       "\n",
       "                       sentence_remove_commas_concat  \\\n",
       "0  Schnieder bounces around with limp wrists  wea...   \n",
       "1  It is an indelible epic American story about t...   \n",
       "2  Mr. Goyer 's loose  unaccountable direction is...   \n",
       "3  Director Nancy Savoca 's no-frills record of a...   \n",
       "4  An average coming-of-age tale elevated by the ...   \n",
       "\n",
       "                       sentence_remove_commas_tokens success_remove_commas  \n",
       "0  [Schnieder, bounces, around, with, limp, wrist...        [1, [[6, 14]]]  \n",
       "1  [It, is, an, indelible, epic, American, story,...       [1, [[10, 16]]]  \n",
       "2  [Mr., Goyer, 's, loose, , unaccountable, direc...            [1, [[4]]]  \n",
       "3  [Director, Nancy, Savoca, 's, no, -, frills, r...                     0  \n",
       "4  [An, average, coming, -, of, -, age, tale, ele...                     0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_perturbations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_perturbations['sentence_tokens'].apply(len) != train_perturbations['sentence_swap_adj_tokens'].apply(len)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      39\n",
       "1      44\n",
       "2      41\n",
       "3      19\n",
       "4       8\n",
       "       ..\n",
       "995    39\n",
       "996    20\n",
       "997    26\n",
       "998    30\n",
       "999    24\n",
       "Name: sentence_change_last_name_tokens, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_perturbations['sentence_change_last_name_tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
