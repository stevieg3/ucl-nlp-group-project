{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up<br>\n",
    "This set-up assumes that the working directory (`os.curdir`) is where the notebook is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T01:06:27.882454Z",
     "iopub.status.busy": "2021-05-16T01:06:27.881680Z",
     "iopub.status.idle": "2021-05-16T01:06:27.884657Z",
     "shell.execute_reply": "2021-05-16T01:06:27.884009Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "this_notebook_dir = os.curdir\n",
    "project_root_dir = os.path.relpath(os.path.join('..', '..'), this_notebook_dir)\n",
    "if project_root_dir not in sys.path:\n",
    "    sys.path += [project_root_dir]\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and model<br>\n",
    "We will now a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T01:06:27.890862Z",
     "iopub.status.busy": "2021-05-16T01:06:27.890029Z",
     "iopub.status.idle": "2021-05-16T01:06:33.815399Z",
     "shell.execute_reply": "2021-05-16T01:06:33.814762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset sst\n"
     ]
    }
   ],
   "source": [
    "from src.data.dataload import *\n",
    "data = load_sst()\n",
    "print(f'loaded dataset {data.NAME}')\n",
    "train, dev, test = data.train_val_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a model for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T01:06:33.820315Z",
     "iopub.status.busy": "2021-05-16T01:06:33.819691Z",
     "iopub.status.idle": "2021-05-16T01:06:40.366435Z",
     "shell.execute_reply": "2021-05-16T01:06:40.365642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignoring warnings from spacy\n",
      "expecting location for the model file at \"../../models/bcn-sst_output/model.tar.gz\"\n",
      "loaded model <src.models.bcnmodel.BCNModel object at 0x7faca645dee0> of type allennlp for sst\n"
     ]
    }
   ],
   "source": [
    "from src.models.bcnmodel import *\n",
    "from src.models.bertmodel import *\n",
    "model = BCNModel()\n",
    "print(f'expecting location for the model file at '\n",
    "      f'\"{model._get_model_filepath_for_dataset(data)}\"')\n",
    "model.load_model(data)\n",
    "print(f'loaded model {model} of type {model.MODELTYPE} for {data.NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainers<br>\n",
    "Creating an explainer for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T01:06:40.370925Z",
     "iopub.status.busy": "2021-05-16T01:06:40.370298Z",
     "iopub.status.idle": "2021-05-16T01:06:41.823531Z",
     "shell.execute_reply": "2021-05-16T01:06:41.822820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using explainer <class 'src.explainers.explainers.LimeExplainer'> with model <src.models.bcnmodel.BCNModel object at 0x7faca645dee0> and dataset sst\n"
     ]
    }
   ],
   "source": [
    "from src.explainers.explainers import *\n",
    "explainer = LimeExplainer(model, num_samples=2000)\n",
    "print(f'using explainer {type(explainer)} with model {explainer.model} and dataset {explainer.model.dataset_finetune.NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T01:06:41.835626Z",
     "iopub.status.busy": "2021-05-16T01:06:41.834993Z",
     "iopub.status.idle": "2021-05-16T01:07:14.919845Z",
     "shell.execute_reply": "2021-05-16T01:07:14.920293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: Half Submarine flick , Half Ghost Story , All in one criminally neglected film\n",
      "tokens [in, All, Ghost, Half, Half, flick, ,, one, Submarine, ,, Story]\n",
      "scores ['0.130', '0.053', '0.039', '0.026', '0.020', '-0.002', '-0.002', '-0.003', '-0.004', '-0.005', '-0.009']\n"
     ]
    }
   ],
   "source": [
    "inds = np.arange(5, 10)\n",
    "X = explainer.explain_instances(dev.sentence[inds])\n",
    "print('SENTENCE:', dev.sentence[inds[0]])\n",
    "tokenized = model.tokenizer.tokenize(dev.sentence[inds[0]])\n",
    "if type(explainer) == LimeExplainer:\n",
    "    scores, pred, inds, tokens = X\n",
    "    print('tokens', [tokenized[t] for t in tokens[0]])\n",
    "    print('scores', ['%.3f' % s for s in scores[0]])\n",
    "elif type(explainer) == SHAPExplainer:\n",
    "    shap_values = X\n",
    "    print('shap values', shap_values[0])\n",
    "elif type(explainer) == AllenNLPExplainer:\n",
    "    grads, labels = X\n",
    "    print(tokenized)\n",
    "    print('gradients', ['%.3f' % g for g in grads[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
